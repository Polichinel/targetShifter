{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy version:  1.24.3\n",
      "PyTorch version:  2.0.1\n",
      "CUDA version:  11.7\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "\n",
    "print(\"NumPy version: \", np.__version__)\n",
    "print(\"PyTorch version: \", torch.__version__)\n",
    "print(\"CUDA version: \", torch.version.cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THE TWO FIRST ALL SHIFT THE WRONG WAY!!! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty the CUDA cache to free up GPU memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timing_decorator(func):\n",
    "\n",
    "    \"\"\" A decorator that times a function and prints the execution time.\"\"\"\n",
    "\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start_time = time.time()\n",
    "        result = func(*args, **kwargs)\n",
    "        end_time = time.time()\n",
    "        execution_time = end_time - start_time\n",
    "        print(f\"{func.__name__} took {execution_time:.6f} seconds to run.\")\n",
    "        return result\n",
    "    \n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@timing_decorator\n",
    "def sort_tensor_by_indices(tensor, primary_index, secondary_index):\n",
    "    \"\"\"\n",
    "    Sort a PyTorch tensor based on both primary and secondary indices.\n",
    "\n",
    "    Args:\n",
    "        tensor (torch.Tensor): The input tensor to be sorted.\n",
    "        primary_index (int): The primary index (column) based on which to sort the tensor. Should be group coulumn\n",
    "        secondary_index (int): The secondary index (column) based on which to sort the tensor. Should be time column\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: The sorted tensor.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If the input is not a PyTorch tensor, or if the primary or secondary index is not a natural number.\n",
    "\n",
    "    \"\"\"\n",
    "    # Check if the input is a PyTorch tensor\n",
    "    if not isinstance(tensor, torch.Tensor):\n",
    "        raise ValueError(\"Input 'tensor' must be a PyTorch tensor.\")\n",
    "    \n",
    "    # Sort based on the secondary index first\n",
    "    sorted_indices_secondary = torch.argsort(tensor[:, secondary_index])\n",
    "    tensor_sorted_secondary = tensor[sorted_indices_secondary]\n",
    "\n",
    "    # Sort based on the primary index\n",
    "    sorted_indices_primary = torch.argsort(tensor_sorted_secondary[:, primary_index])\n",
    "    final_sorted_tensor = tensor_sorted_secondary[sorted_indices_primary]\n",
    "\n",
    "    return final_sorted_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@timing_decorator\n",
    "def shuffle_tensor_rows(tensor):\n",
    "    \"\"\"\n",
    "    Shuffle the rows of a PyTorch tensor. Just for testing the sorting function.\n",
    "\n",
    "    Args:\n",
    "        tensor (torch.Tensor): The input tensor to be shuffled.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: The shuffled tensor.\n",
    "\n",
    "    \"\"\"\n",
    "    # Generate random indices for shuffling\n",
    "    random_indices = torch.randperm(tensor.size(0))\n",
    "\n",
    "    # Shuffle the tensor using the random indices\n",
    "    shuffled_tensor = tensor[random_indices]\n",
    "\n",
    "    return shuffled_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "@timing_decorator\n",
    "def check_if_subset(data, new_data):\n",
    "    \"\"\"\n",
    "    Check if new_data is a subset of the original data by comparing specific columns.\n",
    "\n",
    "    Args:\n",
    "        data (torch.Tensor): Original data tensor.\n",
    "        new_data (torch.Tensor): Data to be checked for subset.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if new_data is a subset of the original data; False otherwise.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Calculate the sum of specific columns\n",
    "    sum_col = data[:, 2] + data[:, -1]  # group column + target column\n",
    "    new_sum_col = new_data[:, 2] + new_data[:, -1]  # group column + target column\n",
    "\n",
    "    # Check if new_sum_col is a subset of sum_col\n",
    "    is_subset = torch.all(torch.isin(new_sum_col.cpu(), sum_col))\n",
    "\n",
    "    if is_subset:\n",
    "        print(\"The new column is a subset of the original column.\")\n",
    "    else:\n",
    "        print(\"The new column is NOT a subset of the original column.\")\n",
    "\n",
    "    return is_subset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "@timing_decorator\n",
    "def check_if_length_correct(data, new_data, steps):\n",
    "    \"\"\"\n",
    "    Check if the number of censored rows in new_data is correct by comparing it with the expected value.\n",
    "\n",
    "    Args:\n",
    "        data (torch.Tensor): Original data tensor.\n",
    "        new_data (torch.Tensor): Data processed by the shift_and_mask_column function.\n",
    "        steps (int): Number of steps to shift the specified column down.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the number of censored rows in new_data is correct; False otherwise.\n",
    "    \"\"\"\n",
    "\n",
    "    num_groups = torch.unique(data[:, 2]).shape[0]\n",
    "    num_row_censured = num_groups * abs(steps)\n",
    "\n",
    "    length_diff = data.shape[0] - new_data.shape[0]\n",
    "\n",
    "    is_lenght_correct = length_diff == num_row_censured\n",
    "\n",
    "    if is_lenght_correct:\n",
    "        print(\"The number of rows censured is correct.\")\n",
    "    else:\n",
    "        print(\"The number of rows censured is incorrect.\")\n",
    "\n",
    "    return is_lenght_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@timing_decorator\n",
    "def generate_synthetic_temporal_dataset(num_groups=3, num_time_steps=5, num_features=1):\n",
    "    \"\"\"\n",
    "    Generate a synthetic temporal dataset with cumulative target values.\n",
    "\n",
    "    Parameters:\n",
    "    - num_groups (int): Number of groups.\n",
    "    - num_time_steps (int): Number of time steps.\n",
    "    - num_features (int): Number of feature columns.\n",
    "\n",
    "    Returns:\n",
    "    - synthetic_dataset (numpy.ndarray): The synthetic dataset with columns for index, time index, group id, features, and target.\n",
    "    \"\"\"\n",
    "    \n",
    "    n_rows = num_groups * num_time_steps\n",
    "    \n",
    "    # Generate the group id column as a repeat pattern\n",
    "    group_array = np.repeat(np.arange(num_groups), num_time_steps)\n",
    "    \n",
    "    # Generate the time index column as a repeat pattern\n",
    "    time_array = np.tile(np.arange(num_time_steps), num_groups)\n",
    "    \n",
    "    # Generate random feature columns\n",
    "    feature_array = np.random.rand(n_rows, num_features)\n",
    "    \n",
    "    # Generate the index column\n",
    "    indx_array = np.arange(n_rows)\n",
    "    \n",
    "    # Initialize the target column with random values\n",
    "    target_array = np.random.rand(n_rows, 1)\n",
    "    \n",
    "    # Combine all columns into a single numpy array\n",
    "    synthetic_dataset = np.column_stack((indx_array, time_array, group_array, feature_array, target_array))\n",
    "    \n",
    "    return synthetic_dataset\n",
    "\n",
    "# Example usage:\n",
    "# synthetic_data = generate_synthetic_temporal_dataset(num_groups=3, num_time_steps=5, num_features=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shifters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# most memory efficient\n",
    "\n",
    "@timing_decorator\n",
    "def lead_column_within_groups0(data_org, steps_to_lead=1, column_to_lead=-1, time_column = 1, group_column=2, return_full= False, force_cpu=False):\n",
    "    \"\"\"\n",
    "    Lead (shift down) a specified column within each group in a 2D PyTorch tensor, optionally dropping rows with NaN values induced by the leading operation.\n",
    "    Note: there should be no NaN values in the specified column before leading!\n",
    "\n",
    "    Parameters:\n",
    "    - data_org (torch.Tensor): The original 2D PyTorch tensor. If numpy.ndarray, it will be converted to a PyTorch tensor.\n",
    "    - column_to_lead (int): The index of the column to be led within each group. This should be the target column.\n",
    "    - time_column (int): The index of the column that represents the time index.\n",
    "    - group_column (int): The index of the column that represents the groups.\n",
    "    - steps_to_lead (int, optional): The number of steps to lead (default is 1).\n",
    "    - return_full (bool, optional): Whether to return the full data with NaN rows included (default is False). Nice for testing and debugging.\n",
    "    - force_cpu (bool, optional): Whether to force the data to be on the CPU (default is False). Might be needed for large datasets on small GPUs.\n",
    "\n",
    "    Returns:\n",
    "    - data (torch.Tensor): The modified data with the specified column led within each group. If 'return_full' is True, NaN rows are retained.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "    # Convert the input NumPy array to a PyTorch tensor if it is not already\n",
    "    if not isinstance(data_org, torch.Tensor):\n",
    "        data_org = torch.from_numpy(data_org)\n",
    "\n",
    "    data = data_org.clone()\n",
    "\n",
    "    # Move the data to the GPU if available        \n",
    "    if torch.cuda.is_available() and force_cpu == False:\n",
    "        data = data.to('cuda')\n",
    "\n",
    "    # Check that there are no NaN values in the specified column\n",
    "    if torch.isnan(data[:, column_to_lead]).any():\n",
    "        raise ValueError(\"There are NaN values in the specified lead column. Please remove them before leading.\")\n",
    "\n",
    "    # Check that the column to lead is valid\n",
    "    if steps_to_lead <= 0:\n",
    "        raise ValueError(\"Steps to lead must be greater than 0.\")\n",
    "    \n",
    "    if steps_to_lead > data[:, time_column].max():\n",
    "        raise ValueError(f\"Steps to lead must be less than or equal to the maximum time index which appears to be {int(data[:, time_column].max())}.\")\n",
    "\n",
    "    unique_groups = torch.unique(data[:, group_column])\n",
    "\n",
    "    for group in unique_groups:\n",
    "        group_mask = data[:, group_column] == group\n",
    "\n",
    "        # Create a mask to select rows for the current group\n",
    "        group_indices = torch.nonzero(group_mask).flatten()\n",
    "\n",
    "        # Apply leading within the group using slicing\n",
    "        data[group_indices[steps_to_lead:], column_to_lead] = data[group_indices[:-steps_to_lead], column_to_lead]\n",
    "\n",
    "        # Fill in the top rows within each group with a desired value (e.g., nan)\n",
    "        data[group_indices[:steps_to_lead], column_to_lead] = torch.nan\n",
    "\n",
    "    # This is mostly for testing and debugging purposes\n",
    "    if return_full == False: \n",
    "        nan_mask = ~torch.isnan(data[:, column_to_lead])\n",
    "        data = data[nan_mask]\n",
    "    \n",
    "    # return the modified data with the specified column led within each group. If 'return_full' is True, NaN rows are retained otherwise they are dropped.\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fastest\n",
    "\n",
    "@timing_decorator\n",
    "def lead_column_within_groups1(data_org, steps_to_lead=1, column_to_lead=-1, time_column = 1, group_column=2, return_full= False, force_cpu=False):\n",
    "    \"\"\"\n",
    "    Lead (shift down) a specified column within each group in a 2D PyTorch tensor, optionally dropping rows with NaN values induced by the leading operation.\n",
    "    Note: there should be no NaN values in the specified column before leading!\n",
    "\n",
    "    Parameters:\n",
    "    - data_org (torch.Tensor): The original 2D PyTorch tensor. If numpy.ndarray, it will be converted to a PyTorch tensor.\n",
    "    - column_to_lead (int): The index of the column to be led within each group. This should be the target column.\n",
    "    - time_column (int): The index of the column that represents the time index.\n",
    "    - group_column (int): The index of the column that represents the groups.\n",
    "    - steps_to_lead (int, optional): The number of steps to lead (default is 1).\n",
    "    - return_full (bool, optional): Whether to return the full data with NaN rows included (default is False). Nice for testing and debugging.\n",
    "    - force_cpu (bool, optional): Whether to force the data to be on the CPU (default is False). Might be needed for large datasets on small GPUs.\n",
    "\n",
    "    Returns:\n",
    "    - data (torch.Tensor): The modified data with the specified column led within each group. If 'return_full' is True, NaN rows are retained.\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert the input NumPy array to a PyTorch tensor if it is not already\n",
    "    if not isinstance(data_org, torch.Tensor):\n",
    "        data_org = torch.from_numpy(data_org)\n",
    "\n",
    "    data = data_org.clone()\n",
    "\n",
    "    # Move the data to the GPU if available        \n",
    "    if torch.cuda.is_available() and force_cpu == False:\n",
    "        data = data.to('cuda')\n",
    "\n",
    "    elif force_cpu == True:\n",
    "        data = data.clone() \n",
    "\n",
    "    # Check that there are no NaN values in the specified column\n",
    "    if torch.isnan(data[:, column_to_lead]).any():\n",
    "        raise ValueError(\"There are NaN values in the specified lead column. Please remove them before leading.\")\n",
    "\n",
    "    # Check that the column to lead is valid\n",
    "    if steps_to_lead <= 0:\n",
    "        raise ValueError(\"Steps to lead must be greater than 0.\")\n",
    "    \n",
    "    if steps_to_lead > data[:, time_column].max():\n",
    "        raise ValueError(f\"Steps to lead must be less than or equal to the maximum time index which appears to be {int(data[:, time_column].max())}.\")\n",
    "\n",
    "\n",
    "    unique_values, group_indices = data[:, group_column].unique(return_inverse=True)\n",
    "\n",
    "    # Create a mask for each group\n",
    "    group_masks = [group_indices == i for i in range(len(unique_values))]\n",
    "\n",
    "    # Apply the leading operation to the specified column within each group\n",
    "    for group_mask in group_masks:\n",
    "        group_rows = data[group_mask]\n",
    "        nan_tensor = torch.full((steps_to_lead,), float('nan'), dtype=torch.float32).to(data.device)    \n",
    "        shifted_column = torch.cat((nan_tensor, group_rows[:-steps_to_lead, column_to_lead]), dim=0)\n",
    "        data[group_mask, column_to_lead] = shifted_column\n",
    "\n",
    "    # This is mostly for testing and debugging purposes\n",
    "    if return_full == False: \n",
    "        nan_mask = ~torch.isnan(data[:, column_to_lead])\n",
    "        data = data[nan_mask]\n",
    "    \n",
    "    # return the modified data with the specified column led within each group. If 'return_full' is True, NaN rows are retained otherwise they are dropped.\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "@timing_decorator\n",
    "def shift_and_mask_column(data_org, column_to_shift_idx=-1, time_column_idx=1, steps=-1, force_cpu=False, return_full=False):\n",
    "    \"\"\"\n",
    "    Shifts a specified column down by a given number of steps and replaces specific values with NaN.\n",
    "\n",
    "    Args:\n",
    "        data_org (torch.Tensor or numpy.ndarray): Input data tensor. If a numpy array is provided, it will be converted to a torch.Tensor.\n",
    "        column_to_shift_idx (int, optional): Index of the column to be shifted. Default is -1. I.e., the last column which is usually the target column.\n",
    "        time_column_idx (int, optional): Index of the time column. Default is 1.\n",
    "        steps (int, optional): Number of steps to shift the specified column down. Default is -1. I.e. laggging by one step.\n",
    "        force_cpu (bool, optional): If True, forces computation on CPU. Default is False.\n",
    "        return_full (bool, optional): Whether to return the full data with NaN rows included (default is False). Nice for testing and debugging.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Processed data tensor. If 'return_full' is True, NaN rows are retained.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert the input NumPy array to a PyTorch tensor if it is not already\n",
    "    if not isinstance(data_org, torch.Tensor):\n",
    "        data_org = torch.from_numpy(data_org)\n",
    "\n",
    "    data = data_org.clone()\n",
    "\n",
    "    # Move the data to the GPU if available\n",
    "    if torch.cuda.is_available() and not force_cpu:\n",
    "        data = data.to('cuda') # No need to clone since we are moving the data to the GPU\n",
    "    elif force_cpu:\n",
    "        data = data.clone() # Need to clone since we are staying on the CPU\n",
    "\n",
    "    # Extract the column you want to shift\n",
    "    column_to_shift = data[:, column_to_shift_idx]\n",
    "\n",
    "    # Create a shifted version of the column\n",
    "    shifted_column = torch.roll(column_to_shift, shifts=steps, dims=0)  # I could also nan-out stuff before rolling...\n",
    "\n",
    "    # Create a mask to identify values to be replaced with NaN\n",
    "    mask = data[:, time_column_idx] < torch.unique(data[:, time_column_idx])[steps] # Need to check that this is robust - and I do not think it works for leading columns\n",
    "    \n",
    "    # Create a tensor with NaN values\n",
    "    nan_tensor = torch.full_like(shifted_column, float('nan'))\n",
    "\n",
    "    # Apply the mask to replace specific values with NaN\n",
    "    masked_shifted_column = torch.where(mask, shifted_column, nan_tensor)\n",
    "\n",
    "    # Replace the original column with the shifted column\n",
    "    data[:, column_to_shift_idx] = masked_shifted_column\n",
    "\n",
    "        # This is mostly for testing and debugging purposes\n",
    "    if return_full == False: \n",
    "        nan_mask = ~torch.isnan(data[:, column_to_shift_idx])\n",
    "        data = data[nan_mask]\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate_synthetic_temporal_dataset took 0.000360 seconds to run.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000,  0.7269,  0.0693],\n",
       "        [ 1.0000,  1.0000,  0.0000,  0.6099,  0.5575],\n",
       "        [ 2.0000,  2.0000,  0.0000,  0.6151,  0.4719],\n",
       "        [ 3.0000,  3.0000,  0.0000,  0.9330,  0.3078],\n",
       "        [ 4.0000,  0.0000,  1.0000,  0.0298,  0.1915],\n",
       "        [ 5.0000,  1.0000,  1.0000,  0.4825,  0.1551],\n",
       "        [ 6.0000,  2.0000,  1.0000,  0.0657,  0.3784],\n",
       "        [ 7.0000,  3.0000,  1.0000,  0.0918,  0.5381],\n",
       "        [ 8.0000,  0.0000,  2.0000,  0.1473,  0.7178],\n",
       "        [ 9.0000,  1.0000,  2.0000,  0.7832,  0.0554],\n",
       "        [10.0000,  2.0000,  2.0000,  0.2622,  0.2436],\n",
       "        [11.0000,  3.0000,  2.0000,  0.8622,  0.2880]], dtype=torch.float64)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_org = generate_synthetic_temporal_dataset(num_groups=3, num_time_steps=4, num_features=1) # num_groups would be number of unique pg_id, time would be month_id, num_features would be, well, number of features.\n",
    "\n",
    "# Convert the input NumPy array to a PyTorch tensor if it is not already\n",
    "if not isinstance(data_org, torch.Tensor):\n",
    "    data_org = torch.from_numpy(data_org)\n",
    "\n",
    "data = data_org.clone()\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shuffle_tensor_rows took 0.000652 seconds to run.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[11.0000,  3.0000,  2.0000,  0.8622,  0.2880],\n",
       "        [10.0000,  2.0000,  2.0000,  0.2622,  0.2436],\n",
       "        [ 1.0000,  1.0000,  0.0000,  0.6099,  0.5575],\n",
       "        [ 2.0000,  2.0000,  0.0000,  0.6151,  0.4719],\n",
       "        [ 7.0000,  3.0000,  1.0000,  0.0918,  0.5381],\n",
       "        [ 6.0000,  2.0000,  1.0000,  0.0657,  0.3784],\n",
       "        [ 5.0000,  1.0000,  1.0000,  0.4825,  0.1551],\n",
       "        [ 9.0000,  1.0000,  2.0000,  0.7832,  0.0554],\n",
       "        [ 8.0000,  0.0000,  2.0000,  0.1473,  0.7178],\n",
       "        [ 3.0000,  3.0000,  0.0000,  0.9330,  0.3078],\n",
       "        [ 4.0000,  0.0000,  1.0000,  0.0298,  0.1915],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.7269,  0.0693]], dtype=torch.float64)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = shuffle_tensor_rows(data)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sort_tensor_by_indices took 0.001090 seconds to run.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000,  0.7269,  0.0693],\n",
       "        [ 1.0000,  1.0000,  0.0000,  0.6099,  0.5575],\n",
       "        [ 2.0000,  2.0000,  0.0000,  0.6151,  0.4719],\n",
       "        [ 3.0000,  3.0000,  0.0000,  0.9330,  0.3078],\n",
       "        [ 4.0000,  0.0000,  1.0000,  0.0298,  0.1915],\n",
       "        [ 5.0000,  1.0000,  1.0000,  0.4825,  0.1551],\n",
       "        [ 6.0000,  2.0000,  1.0000,  0.0657,  0.3784],\n",
       "        [ 7.0000,  3.0000,  1.0000,  0.0918,  0.5381],\n",
       "        [ 8.0000,  0.0000,  2.0000,  0.1473,  0.7178],\n",
       "        [ 9.0000,  1.0000,  2.0000,  0.7832,  0.0554],\n",
       "        [10.0000,  2.0000,  2.0000,  0.2622,  0.2436],\n",
       "        [11.0000,  3.0000,  2.0000,  0.8622,  0.2880]], dtype=torch.float64)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "primary_index = 2 # group column\n",
    "secondary_index = 1 # time column\n",
    "\n",
    "data = sort_tensor_by_indices(data, primary_index, secondary_index)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shift_and_mask_column took 0.016423 seconds to run.\n"
     ]
    }
   ],
   "source": [
    "steps_to_shift = -1\n",
    "\n",
    "new_data = shift_and_mask_column(data, steps=steps_to_shift,return_full=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The new column is a subset of the original column.\n",
      "check_if_subset took 0.001173 seconds to run.\n",
      "The number of rows censured is correct.\n",
      "check_if_length_correct took 0.000104 seconds to run.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_if_subset(data, new_data)\n",
    "check_if_length_correct(data, new_data, steps_to_shift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLD!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000,  0.7729,  0.0947],\n",
       "        [ 1.0000,  1.0000,  0.0000,  0.7822,  0.8289],\n",
       "        [ 2.0000,  2.0000,  0.0000,  0.4798,  0.4352],\n",
       "        [ 4.0000,  0.0000,  1.0000,  0.1150,  0.5210],\n",
       "        [ 5.0000,  1.0000,  1.0000,  0.5573,  0.2652],\n",
       "        [ 6.0000,  2.0000,  1.0000,  0.0223,  0.2364],\n",
       "        [ 8.0000,  0.0000,  2.0000,  0.6469,  0.6705],\n",
       "        [ 9.0000,  1.0000,  2.0000,  0.5260,  0.9028],\n",
       "        [10.0000,  2.0000,  2.0000,  0.9059,  0.4479]], device='cuda:0',\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_if_subset(data, new_data):\n",
    "    \"\"\"\n",
    "    Check if new_data is a subset of the original data by comparing specific columns.\n",
    "\n",
    "    Args:\n",
    "        data (torch.Tensor): Original data tensor.\n",
    "        new_data (torch.Tensor): Data to be checked for subset.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if new_data is a subset of the original data; False otherwise.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Calculate the sum of specific columns\n",
    "    sum_col = data[:, 2] + data[:, -1]  # group column + target column\n",
    "    new_sum_col = new_data[:, 2] + new_data[:, -1]  # group column + target column\n",
    "\n",
    "    # Check if new_sum_col is a subset of sum_col\n",
    "    is_subset = torch.all(torch.isin(new_sum_col.cpu(), sum_col))\n",
    "\n",
    "    if is_subset:\n",
    "        print(\"The new column is a subset of the original column.\")\n",
    "    else:\n",
    "        print(\"The new column is NOT a subset of the original column.\")\n",
    "\n",
    "    return is_subset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_if_length_correct(data, new_data, steps):\n",
    "    \"\"\"\n",
    "    Check if the number of censored rows in new_data is correct by comparing it with the expected value.\n",
    "\n",
    "    Args:\n",
    "        data (torch.Tensor): Original data tensor.\n",
    "        new_data (torch.Tensor): Data processed by the shift_and_mask_column function.\n",
    "        steps (int): Number of steps to shift the specified column down.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the number of censored rows in new_data is correct; False otherwise.\n",
    "    \"\"\"\n",
    "\n",
    "    num_groups = torch.unique(data[:, 2]).shape[0]\n",
    "    num_row_censured = num_groups * abs(steps)\n",
    "\n",
    "    length_diff = data.shape[0] - new_data.shape[0]\n",
    "\n",
    "    is_lenght_correct = length_diff == num_row_censured\n",
    "\n",
    "    if is_lenght_correct:\n",
    "        print(\"The number of rows censured is correct.\")\n",
    "    else:\n",
    "        print(\"The number of rows censured is incorrect.\")\n",
    "\n",
    "    return is_lenght_correct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The new column is a subset of the original column.\n",
      "The number of rows censured is correct.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_if_subset(data, new_data)\n",
    "check_if_length_correct(data, new_data, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data\n",
    "new_data = new_data\n",
    "steps = -1\n",
    "\n",
    "\n",
    "def check_if_subset(data, new_data):\n",
    "\n",
    "    sum_col = data[:,2] + data[:,-1] # group column + target column\n",
    "    new_sum_col = new_data[:,2] + new_data[:,-1] # group column + target column\n",
    "\n",
    "    # Check if new_sum_col is a subset of sum_col - it should be if the shift_and_mask_column function worked correctly and no values spilled over to the next group\n",
    "    is_subset = torch.all(torch.isin(new_sum_col.cpu(), sum_col))\n",
    "\n",
    "    if is_subset:\n",
    "        print(\"The new col is a subset of original col\")\n",
    "    else:\n",
    "        print(\"The new col is NOT a subset of original col\")\n",
    "\n",
    "\n",
    "def check_if_lenght_correct(data, new_data, steps):\n",
    "\n",
    "    num_groups = torch.unique(data[:, 2]).shape[0]\n",
    "    num_row_censured = num_groups * abs(steps)\n",
    "    num_row_censured\n",
    "\n",
    "    length_diff = data.shape[0] - new_data.shape[0]\n",
    "\n",
    "    if length_diff == num_row_censured:\n",
    "        print(\"The number of rows censured is correct.\")    \n",
    "\n",
    "    else:\n",
    "        print(\"The number of rows censured is INcorrect.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of rows censured is correct.\n",
      "The new col is a subset of original col\n"
     ]
    }
   ],
   "source": [
    "check_if_lenght_correct(data, new_data, steps)\n",
    "check_if_subset(data, new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of rows censured is correct.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_row_censured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate_synthetic_temporal_dataset took 4.134680 seconds to run.\n"
     ]
    }
   ],
   "source": [
    "data_org = generate_synthetic_temporal_dataset(num_groups=15000, num_time_steps=400, num_features=100) # num_groups would be number of unique pg_id, time would be month_id, num_features would be, well, number of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shift_and_mask_column took 0.024520 seconds to run.\n"
     ]
    }
   ],
   "source": [
    "_ = shift_and_mask_column(data, steps=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_small_df(steps_to_lead=1):\n",
    "    \"\"\"\n",
    "    A visial sanity test of the lead_column_within_groups function on a small dataset with 2 groups and 5 time steps and 1 feature column.\n",
    "    You should see the target column led by \"steps_to_lead\" steps within each group in the second to last column.\n",
    "    The original target column is also printed for comparison as the last column. This only happens in this function for testing purposes.\n",
    "    \"\"\"\n",
    "    # Create a small dataset\n",
    "    small_df = generate_synthetic_temporal_dataset(num_groups=2, num_time_steps=5, num_features=1)\n",
    "\n",
    "    original_taget = torch.from_numpy(small_df[:, -1][:, np.newaxis])\n",
    "    if torch.cuda.is_available():\n",
    "        original_taget = original_taget.to('cuda')\n",
    "\n",
    "    # Lead the target column within each group by 1 step\n",
    "   \n",
    "    small_df0 = lead_column_within_groups0(data_org=small_df, steps_to_lead=steps_to_lead, column_to_lead=-1, time_column = 1, group_column=2, return_full= True)\n",
    "    small_df0 = torch.cat((small_df0, original_taget), dim=1)\n",
    "\n",
    "    # Print the results\n",
    "    print()\n",
    "    print(\"Version 0, the most memory efficient\")\n",
    "    print(small_df0)\n",
    "    print()\n",
    "\n",
    "    small_df1 = lead_column_within_groups1(data_org=small_df, steps_to_lead=steps_to_lead, column_to_lead=-1, time_column = 1, group_column=2, return_full= True)\n",
    "    small_df1 = torch.cat((small_df1, original_taget), dim=1)\n",
    "\n",
    "    print(\"Version 1, the fastest\")\n",
    "    print(small_df0)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_small_df(steps_to_lead=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = generate_synthetic_temporal_dataset(num_groups=3000, num_time_steps=400, num_features=100) # num_groups would be number of unique pg_id, time would be month_id, num_features would be, well, number of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = lead_column_within_groups0(data, steps_to_lead = 1, return_full=False) # with 8gb gpu, I cannot handle much more than 10000 groups, 400 time steps and 100 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = lead_column_within_groups1(data, steps_to_lead = 1, return_full=False) # with 8gb gpu, I cannot handle much more than 3000 groups, 400 time steps and 100 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = lead_column_within_groups0(data, steps_to_lead = 1, return_full=False, force_cpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = lead_column_within_groups1(data, steps_to_lead = 1, return_full=False, force_cpu=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "next solution:\n",
    "\n",
    "just roll the lead column s steps and then maks it with a nan mask matching the first s rows for each group. Imortant for this solutions that you sort by group first"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WORING:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! LOOPLESS !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "# Needs updated documentation and looots of testing...\n",
    "\n",
    "\n",
    "@timing_decorator\n",
    "def shift_and_mask_column(data_org, column_to_shift_idx = -1, time_column_idx = 1, steps=-1, force_cpu=False):\n",
    "    \"\"\"\n",
    "    Shifts a specified column down by a number of steps and replaces specific values with NaN.\n",
    "\n",
    "    Args:\n",
    "        data (torch.Tensor): Input data tensor.\n",
    "        column_to_shift_idx (int): Index of the column to be shifted.\n",
    "        time_column_idx (int): Index of the time column.\n",
    "        steps (int, optional): Number of steps to shift the specified column down. Default is -1.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Processed data tensor.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert the input NumPy array to a PyTorch tensor if it is not already\n",
    "    if not isinstance(data_org, torch.Tensor):\n",
    "        data_org = torch.from_numpy(data_org)\n",
    "\n",
    "    data = data_org.clone()\n",
    "\n",
    "    # Move the data to the GPU if available        \n",
    "    if torch.cuda.is_available() and force_cpu == False:\n",
    "        data = data.to('cuda')\n",
    "\n",
    "    elif force_cpu == True:\n",
    "        data = data.clone() \n",
    "\n",
    "    # Extract the column you want to shift\n",
    "    column_to_shift = data[:, column_to_shift_idx]\n",
    "\n",
    "    # Create a shifted version of the column\n",
    "    shifted_column = torch.roll(column_to_shift, shifts=steps, dims=0)\n",
    "\n",
    "    mask = data[:, time_column_idx] < torch.unique(data[:,1])[steps]\n",
    "\n",
    "    # Create a tensor with NaN values\n",
    "    nan_tensor = torch.full_like(shifted_column, float('nan'))\n",
    "\n",
    "    # Apply the mask to replace specific values with NaN\n",
    "    masked_shifted_column = torch.where(mask, shifted_column, nan_tensor)\n",
    "\n",
    "    # Replace the original column with the shifted column\n",
    "    data[:, column_to_shift_idx] = masked_shifted_column\n",
    "\n",
    "    return data\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_2023",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
