{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy version:  1.24.3\n",
      "PyTorch version:  2.0.1\n",
      "CUDA version:  11.7\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "\n",
    "print(\"NumPy version: \", np.__version__)\n",
    "print(\"PyTorch version: \", torch.__version__)\n",
    "print(\"CUDA version: \", torch.version.cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timing_decorator(func):\n",
    "\n",
    "    \"\"\" A decorator that times a function and prints the execution time.\"\"\"\n",
    "\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start_time = time.time()\n",
    "        result = func(*args, **kwargs)\n",
    "        end_time = time.time()\n",
    "        execution_time = end_time - start_time\n",
    "        print(f\"{func.__name__} took {execution_time:.6f} seconds to run.\")\n",
    "        return result\n",
    "    \n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@timing_decorator\n",
    "def sort_tensor_by_indices(tensor, primary_index, secondary_index):\n",
    "    \"\"\"\n",
    "    Sort a PyTorch tensor based on both primary and secondary indices. This function is vital since the shifter requires the input tensor to be sorted by both group and time.\n",
    "\n",
    "    Args:\n",
    "        tensor (torch.Tensor): The input tensor to be sorted.\n",
    "        primary_index (int): The primary index (column) based on which to sort the tensor. Should be group coulumn\n",
    "        secondary_index (int): The secondary index (column) based on which to sort the tensor. Should be time column\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: The sorted tensor.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If the input is not a PyTorch tensor, or if the primary or secondary index is not a natural number.\n",
    "\n",
    "    \"\"\"\n",
    "    # # Check if the input is a PyTorch tensor\n",
    "    #if not isinstance(tensor, torch.Tensor) or not isinstance(tensor, np.ndarray):\n",
    "    #    raise ValueError(\"Input 'tensor' must be a PyTorch tensor or numpy array!\")\n",
    "\n",
    "\n",
    "    # Sort by both columns using NumPy's lexsort\n",
    "    sorted_indices = np.lexsort((tensor[:, secondary_index], tensor[:,primary_index])) # torch does not have lexsort. Use numpy instead\n",
    "\n",
    "    # Apply the sorting order to the original PyTorch tensor\n",
    "    sorted_tensor = tensor[sorted_indices]\n",
    "\n",
    "    return sorted_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@timing_decorator\n",
    "def shuffle_tensor_rows(tensor):\n",
    "    \"\"\"\n",
    "    Shuffle the rows of a PyTorch tensor. Just for testing the sorting function.\n",
    "\n",
    "    Args:\n",
    "        tensor (torch.Tensor): The input tensor to be shuffled.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: The shuffled tensor.\n",
    "\n",
    "    \"\"\"\n",
    "    # Generate random indices for shuffling\n",
    "    random_indices = torch.randperm(tensor.size(0))\n",
    "\n",
    "    # Shuffle the tensor using the random indices\n",
    "    shuffled_tensor = tensor[random_indices]\n",
    "\n",
    "    return shuffled_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@timing_decorator\n",
    "def check_if_subset(data, new_data):\n",
    "    \"\"\"\n",
    "    Check if new_data is a subset of the original data by comparing specific columns.\n",
    "    Adds up the group column and target column of the original data and the new data. \n",
    "    If the shifting and censoring is done correctly, the new column should be a subset of the original column.\n",
    "\n",
    "    Args:\n",
    "        data (torch.Tensor): Original data tensor.\n",
    "        new_data (torch.Tensor): Data to be checked for subset.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if new_data is a subset of the original data; False otherwise.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Calculate the sum of specific columns\n",
    "    sum_col = data[:, 2] + data[:, -1]  # group column + target column\n",
    "    new_sum_col = new_data[:, 2] + new_data[:, -1]  # group column + target column\n",
    "\n",
    "    # Check if new_sum_col is a subset of sum_col\n",
    "    is_subset = torch.all(torch.isin(new_sum_col.cpu(), sum_col.cpu()))\n",
    "\n",
    "    if is_subset:\n",
    "        print(\"The new column is a subset of the original column.\")\n",
    "    else:\n",
    "        print(\"The new column is NOT a subset of the original column.\")\n",
    "\n",
    "    return is_subset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@timing_decorator\n",
    "def check_if_length_correct(data, new_data, steps):\n",
    "    \"\"\"\n",
    "    Check if the number of censored rows in new_data is correct by comparing it with the expected value.\n",
    "\n",
    "    Args:\n",
    "        data (torch.Tensor): Original data tensor.\n",
    "        new_data (torch.Tensor): Data processed by the shift_and_mask_column function.\n",
    "        steps (int): Number of steps to shift the specified column down.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the number of censored rows in new_data is correct; False otherwise.\n",
    "    \"\"\"\n",
    "\n",
    "    num_groups = torch.unique(data[:, 2]).shape[0]\n",
    "    num_row_censured = num_groups * abs(steps)\n",
    "\n",
    "    length_diff = data.shape[0] - new_data.shape[0]\n",
    "\n",
    "    is_lenght_correct = length_diff == num_row_censured\n",
    "\n",
    "    if is_lenght_correct:\n",
    "        print(\"The number of rows censured is correct.\")\n",
    "    else:\n",
    "        print(\"The number of rows censured is incorrect.\")\n",
    "\n",
    "    return is_lenght_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@timing_decorator\n",
    "def generate_synthetic_temporal_dataset(num_groups=3, num_time_steps=5, num_features=1):\n",
    "    \"\"\"\n",
    "    Generate a synthetic temporal dataset with cumulative target values.\n",
    "\n",
    "    Parameters:\n",
    "    - num_groups (int): Number of groups.\n",
    "    - num_time_steps (int): Number of time steps.\n",
    "    - num_features (int): Number of feature columns.\n",
    "\n",
    "    Returns:\n",
    "    - synthetic_dataset (numpy.ndarray): The synthetic dataset with columns for index, time index, group id, features, and target.\n",
    "    \"\"\"\n",
    "    \n",
    "    n_rows = num_groups * num_time_steps\n",
    "    \n",
    "    # Generate the group id column as a repeat pattern\n",
    "    group_array = np.repeat(np.arange(num_groups), num_time_steps)\n",
    "    \n",
    "    # Generate the time index column as a repeat pattern\n",
    "    time_array = np.tile(np.arange(num_time_steps), num_groups)\n",
    "    \n",
    "    # Generate random feature columns\n",
    "    feature_array = np.random.rand(n_rows, num_features)\n",
    "    \n",
    "    # Generate the index column\n",
    "    indx_array = np.arange(n_rows)\n",
    "    \n",
    "    # Initialize the target column with random values\n",
    "    target_array = np.random.rand(n_rows, 1)\n",
    "    \n",
    "    # Combine all columns into a single numpy array\n",
    "    synthetic_dataset = np.column_stack((indx_array, time_array, group_array, feature_array, target_array))\n",
    "    \n",
    "    return synthetic_dataset\n",
    "\n",
    "# Example usage:\n",
    "# synthetic_data = generate_synthetic_temporal_dataset(num_groups=3, num_time_steps=5, num_features=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shifter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "@timing_decorator\n",
    "def shift_and_mask_column(data_org, column_to_shift_idx=-1, time_column_idx=1, steps= 1, force_cpu=False, return_full=False, retain_unshifted_col = False):\n",
    "    \"\"\"\n",
    "    Shifts a specified column down by a given number of steps and replaces specific values with NaN.\n",
    "\n",
    "    Args:\n",
    "        data_org (torch.Tensor or numpy.ndarray): Input data tensor. If a numpy array is provided, it will be converted to a torch.Tensor.\n",
    "        column_to_shift_idx (int, optional): Index of the column to be shifted. Default is -1. I.e., the last column which is usually the target column.\n",
    "        time_column_idx (int, optional): Index of the time column. Default is 1.\n",
    "        steps (int, optional): Number of steps to shift the specified column down. Default is 1. I.e. laggging by one step.\n",
    "        force_cpu (bool, optional): If True, forces computation on CPU. Default is False.\n",
    "        return_full (bool, optional): Whether to return the full data with NaN rows included (default is False). Nice for testing and debugging.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Processed data tensor. If 'return_full' is True, NaN rows are retained.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # # Convert the input NumPy array to a PyTorch tensor if it is not already\n",
    "    if not isinstance(data_org, torch.Tensor):\n",
    "        data_org = torch.from_numpy(data_org)\n",
    "\n",
    "    # Move the data to the GPU if available\n",
    "    if torch.cuda.is_available() and not force_cpu:\n",
    "        data = data_org.to('cuda') # No need to clone since we are moving the data to the GPU\n",
    "\n",
    "    elif force_cpu:\n",
    "        data = data_org.clone() # Need to clone since we are staying on the CPU\n",
    "\n",
    "\n",
    "    unique_time_idx = torch.unique(data[:, time_column_idx])  \n",
    "    time_values_to_mask = torch.sort(unique_time_idx).values[:steps]\n",
    "    time_values_mask = torch.isin(data[:, time_column_idx], time_values_to_mask)\n",
    "    column_to_shift = data[:, -time_column_idx]\n",
    "    masked_column_to_shift = torch.where(~time_values_mask, column_to_shift, torch.full_like(column_to_shift, float('nan')))\n",
    "\n",
    "    masked_column_shifted = torch.roll(masked_column_to_shift, shifts = - steps, dims=0) # needs negative steps here to lag and not lead.\n",
    "\n",
    "\n",
    "    if retain_unshifted_col == False:\n",
    "    # Replace the original column with the shifted column\n",
    "        data[:, column_to_shift_idx] = masked_column_shifted\n",
    "\n",
    "    else:\n",
    "        data = torch.column_stack([data, masked_column_shifted])\n",
    "    \n",
    "    # This is mostly for testing and debugging purposes\n",
    "    if return_full == False: \n",
    "        nan_mask = ~torch.isnan(data[:, column_to_shift_idx])\n",
    "        data = data[nan_mask]\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTING!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_tests(steps_to_shift = 1):\n",
    "\n",
    "    # num_groups would be number of unique pg_id, time would be month_id, num_features would be, well, number of features.\n",
    "    data_org = generate_synthetic_temporal_dataset(num_groups=15000, num_time_steps=400, num_features=100) \n",
    "\n",
    "    # Convert the input NumPy array to a PyTorch tensor if it is not already - should nut be here...\n",
    "    if not isinstance(data_org, torch.Tensor):\n",
    "        data_org = torch.from_numpy(data_org)\n",
    "\n",
    "    data_org = shuffle_tensor_rows(data_org) # to test the sorting function\n",
    "\n",
    "    primary_index = 2 # group column\n",
    "    secondary_index = 1 # time column\n",
    "    data_org = sort_tensor_by_indices(data_org, primary_index, secondary_index) # this step is paramount for the rolling done in shift_and_mask_column to be accurate\n",
    "\n",
    "\n",
    "    new_data = shift_and_mask_column(data_org, steps=steps_to_shift, return_full=False, force_cpu=True) # force CPU now since GPU runs out of mem. Fix later.\n",
    "\n",
    "    print()\n",
    "    test1  = check_if_subset(data_org, new_data)\n",
    "    print()\n",
    "    test2 = check_if_length_correct(data_org, new_data, steps_to_shift)\n",
    "\n",
    "\n",
    "    if test1 and test2:\n",
    "        print(\"\\nAll tests passed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate_synthetic_temporal_dataset took 3.836895 seconds to run.\n",
      "shuffle_tensor_rows took 0.447205 seconds to run.\n",
      "sort_tensor_by_indices took 1.864262 seconds to run.\n",
      "shift_and_mask_column took 1.272718 seconds to run.\n",
      "\n",
      "The new column is a subset of the original column.\n",
      "check_if_subset took 5.635707 seconds to run.\n",
      "\n",
      "The number of rows censured is correct.\n",
      "check_if_length_correct took 0.055111 seconds to run.\n",
      "\n",
      "All tests passed!\n"
     ]
    }
   ],
   "source": [
    "run_tests(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate_synthetic_temporal_dataset took 3.941547 seconds to run.\n",
      "shuffle_tensor_rows took 0.412981 seconds to run.\n",
      "sort_tensor_by_indices took 1.831906 seconds to run.\n",
      "shift_and_mask_column took 0.860739 seconds to run.\n",
      "\n",
      "The new column is a subset of the original column.\n",
      "check_if_subset took 5.596295 seconds to run.\n",
      "\n",
      "The number of rows censured is correct.\n",
      "check_if_length_correct took 0.052355 seconds to run.\n",
      "\n",
      "All tests passed!\n"
     ]
    }
   ],
   "source": [
    "run_tests(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate_synthetic_temporal_dataset took 3.894655 seconds to run.\n",
      "shuffle_tensor_rows took 0.475444 seconds to run.\n",
      "sort_tensor_by_indices took 1.857387 seconds to run.\n",
      "shift_and_mask_column took 0.869786 seconds to run.\n",
      "\n",
      "The new column is a subset of the original column.\n",
      "check_if_subset took 5.534508 seconds to run.\n",
      "\n",
      "The number of rows censured is correct.\n",
      "check_if_length_correct took 0.053815 seconds to run.\n",
      "\n",
      "All tests passed!\n"
     ]
    }
   ],
   "source": [
    "run_tests(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate_synthetic_temporal_dataset took 3.881997 seconds to run.\n",
      "shuffle_tensor_rows took 0.419707 seconds to run.\n",
      "sort_tensor_by_indices took 1.851285 seconds to run.\n",
      "shift_and_mask_column took 0.860537 seconds to run.\n",
      "\n",
      "The new column is a subset of the original column.\n",
      "check_if_subset took 5.571023 seconds to run.\n",
      "\n",
      "The number of rows censured is correct.\n",
      "check_if_length_correct took 0.048917 seconds to run.\n",
      "\n",
      "All tests passed!\n"
     ]
    }
   ],
   "source": [
    "run_tests(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viz_test(steps_to_shift = 1):\n",
    "\n",
    "    data_org = generate_synthetic_temporal_dataset(num_groups=5, num_time_steps=4, num_features=1) \n",
    "\n",
    "    # Convert the input NumPy array to a PyTorch tensor if it is not already - should nut be here...\n",
    "    if not isinstance(data_org, torch.Tensor):\n",
    "        data_org = torch.from_numpy(data_org)\n",
    "\n",
    "    data_org = shuffle_tensor_rows(data_org) # to test the sorting function\n",
    "\n",
    "    primary_index = 2 # group column\n",
    "    secondary_index = 1 # time column\n",
    "    data_org = sort_tensor_by_indices(data_org, primary_index, secondary_index) # this step is paramount for the rolling done in shift_and_mask_column to be accurate\n",
    "\n",
    "    new_data = shift_and_mask_column(data_org, steps=steps_to_shift, return_full=True, force_cpu=True, retain_unshifted_col=True) # force CPU now since GPU runs out of mem. Fix later.\n",
    "\n",
    "    print()\n",
    "    print(new_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate_synthetic_temporal_dataset took 0.000117 seconds to run.\n",
      "shuffle_tensor_rows took 0.000113 seconds to run.\n",
      "sort_tensor_by_indices took 0.000403 seconds to run.\n",
      "shift_and_mask_column took 0.002195 seconds to run.\n",
      "\n",
      "tensor([[ 0.0000,  0.0000,  0.0000,  0.8756,  0.8129,  0.7878],\n",
      "        [ 1.0000,  1.0000,  0.0000,  0.7367,  0.7878,  0.6556],\n",
      "        [ 2.0000,  2.0000,  0.0000,  0.5285,  0.6556,  0.2438],\n",
      "        [ 3.0000,  3.0000,  0.0000,  0.4179,  0.2438,     nan],\n",
      "        [ 4.0000,  0.0000,  1.0000,  0.1165,  0.2763,  0.5425],\n",
      "        [ 5.0000,  1.0000,  1.0000,  0.9187,  0.5425,  0.0457],\n",
      "        [ 6.0000,  2.0000,  1.0000,  0.1132,  0.0457,  0.2634],\n",
      "        [ 7.0000,  3.0000,  1.0000,  0.6321,  0.2634,     nan],\n",
      "        [ 8.0000,  0.0000,  2.0000,  0.7566,  0.2106,  0.4109],\n",
      "        [ 9.0000,  1.0000,  2.0000,  0.7207,  0.4109,  0.5155],\n",
      "        [10.0000,  2.0000,  2.0000,  0.9400,  0.5155,  0.4699],\n",
      "        [11.0000,  3.0000,  2.0000,  0.1085,  0.4699,     nan],\n",
      "        [12.0000,  0.0000,  3.0000,  0.8940,  0.5160,  0.2822],\n",
      "        [13.0000,  1.0000,  3.0000,  0.9309,  0.2822,  0.2665],\n",
      "        [14.0000,  2.0000,  3.0000,  0.4090,  0.2665,  0.2748],\n",
      "        [15.0000,  3.0000,  3.0000,  0.7342,  0.2748,     nan],\n",
      "        [16.0000,  0.0000,  4.0000,  0.5169,  0.8157,  0.7391],\n",
      "        [17.0000,  1.0000,  4.0000,  0.3103,  0.7391,  0.7414],\n",
      "        [18.0000,  2.0000,  4.0000,  0.3733,  0.7414,  0.5414],\n",
      "        [19.0000,  3.0000,  4.0000,  0.8854,  0.5414,     nan]],\n",
      "       dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "viz_test(1) # lag by 1 step. Remember that column 2 is the group column and column 1 is the time column while 0 is the index column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate_synthetic_temporal_dataset took 0.000229 seconds to run.\n",
      "shuffle_tensor_rows took 0.000238 seconds to run.\n",
      "sort_tensor_by_indices took 0.000248 seconds to run.\n",
      "shift_and_mask_column took 0.000277 seconds to run.\n",
      "\n",
      "tensor([[ 0.0000,  0.0000,  0.0000,  0.7917,  0.7443,  0.0229],\n",
      "        [ 1.0000,  1.0000,  0.0000,  0.0465,  0.1550,  0.1394],\n",
      "        [ 2.0000,  2.0000,  0.0000,  0.4313,  0.0229,     nan],\n",
      "        [ 3.0000,  3.0000,  0.0000,  0.2962,  0.1394,     nan],\n",
      "        [ 4.0000,  0.0000,  1.0000,  0.0968,  0.4952,  0.3835],\n",
      "        [ 5.0000,  1.0000,  1.0000,  0.5813,  0.9874,  0.9790],\n",
      "        [ 6.0000,  2.0000,  1.0000,  0.8565,  0.3835,     nan],\n",
      "        [ 7.0000,  3.0000,  1.0000,  0.2171,  0.9790,     nan],\n",
      "        [ 8.0000,  0.0000,  2.0000,  0.7208,  0.2359,  0.0660],\n",
      "        [ 9.0000,  1.0000,  2.0000,  0.7603,  0.2580,  0.3006],\n",
      "        [10.0000,  2.0000,  2.0000,  0.8957,  0.0660,     nan],\n",
      "        [11.0000,  3.0000,  2.0000,  0.4017,  0.3006,     nan],\n",
      "        [12.0000,  0.0000,  3.0000,  0.4752,  0.3519,  0.0659],\n",
      "        [13.0000,  1.0000,  3.0000,  0.5668,  0.9939,  0.1921],\n",
      "        [14.0000,  2.0000,  3.0000,  0.1582,  0.0659,     nan],\n",
      "        [15.0000,  3.0000,  3.0000,  0.2929,  0.1921,     nan],\n",
      "        [16.0000,  0.0000,  4.0000,  0.5616,  0.3629,  0.1605],\n",
      "        [17.0000,  1.0000,  4.0000,  0.3106,  0.0371,  0.4028],\n",
      "        [18.0000,  2.0000,  4.0000,  0.9667,  0.1605,     nan],\n",
      "        [19.0000,  3.0000,  4.0000,  0.7548,  0.4028,     nan]],\n",
      "       dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "viz_test(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate_synthetic_temporal_dataset took 0.000373 seconds to run.\n",
      "shuffle_tensor_rows took 0.000132 seconds to run.\n",
      "sort_tensor_by_indices took 0.000084 seconds to run.\n",
      "shift_and_mask_column took 0.000159 seconds to run.\n",
      "\n",
      "tensor([[ 0.0000,  0.0000,  0.0000,  0.4698,  0.5509,  0.5347],\n",
      "        [ 1.0000,  1.0000,  0.0000,  0.6937,  0.9644,     nan],\n",
      "        [ 2.0000,  2.0000,  0.0000,  0.7465,  0.3936,     nan],\n",
      "        [ 3.0000,  3.0000,  0.0000,  0.1871,  0.5347,     nan],\n",
      "        [ 4.0000,  0.0000,  1.0000,  0.0921,  0.4029,  0.2876],\n",
      "        [ 5.0000,  1.0000,  1.0000,  0.0369,  0.0663,     nan],\n",
      "        [ 6.0000,  2.0000,  1.0000,  0.5445,  0.1087,     nan],\n",
      "        [ 7.0000,  3.0000,  1.0000,  0.4566,  0.2876,     nan],\n",
      "        [ 8.0000,  0.0000,  2.0000,  0.8035,  0.9868,  0.0342],\n",
      "        [ 9.0000,  1.0000,  2.0000,  0.5276,  0.7462,     nan],\n",
      "        [10.0000,  2.0000,  2.0000,  0.2500,  0.2717,     nan],\n",
      "        [11.0000,  3.0000,  2.0000,  0.3406,  0.0342,     nan],\n",
      "        [12.0000,  0.0000,  3.0000,  0.2547,  0.5931,  0.5589],\n",
      "        [13.0000,  1.0000,  3.0000,  0.2675,  0.3037,     nan],\n",
      "        [14.0000,  2.0000,  3.0000,  0.7191,  0.8795,     nan],\n",
      "        [15.0000,  3.0000,  3.0000,  0.9854,  0.5589,     nan],\n",
      "        [16.0000,  0.0000,  4.0000,  0.1530,  0.6169,  0.0804],\n",
      "        [17.0000,  1.0000,  4.0000,  0.5543,  0.0291,     nan],\n",
      "        [18.0000,  2.0000,  4.0000,  0.4356,  0.5710,     nan],\n",
      "        [19.0000,  3.0000,  4.0000,  0.8073,  0.0804,     nan]],\n",
      "       dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "viz_test(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_2023",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
